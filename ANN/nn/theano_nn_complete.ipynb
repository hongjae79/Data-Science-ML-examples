{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pandas as pd\n",
    "\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano.tensor.nnet.bn import batch_normalization_train, batch_normalization_test\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data = df.values.astype(np.float32)\n",
    "np.random.shuffle(data)\n",
    "X = data[:, 1:]\n",
    "Y = data[:, 0]\n",
    "\n",
    "Xtrain = X[:-1000]\n",
    "Ytrain = Y[:-1000]\n",
    "Xtest  = X[-1000:]\n",
    "Ytest  = Y[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = np.reshape(Xtrain[0], (28, 28))\n",
    "plt.imshow(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizie the data\n",
    "\n",
    "mu = Xtrain.mean(axis=0)\n",
    "std = Xtrain.std(axis=0)\n",
    "\n",
    "np.place(std, std == 0, 1)\n",
    "\n",
    "Xtrain = (Xtrain - mu) / std\n",
    "Xtest = (Xtest - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change y to hot encoder\n",
    "\n",
    "def y2indicator(y):\n",
    "\n",
    "    y = y.astype(np.int32)\n",
    "    ind = np.zeros((len(y), 10))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        ind[i, y[i]] = 1\n",
    "        \n",
    "    return ind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return a * (a > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_ind = y2indicator(Ytrain)\n",
    "Ytest_ind = y2indicator(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is ready\n",
    "\n",
    "Xtrain = Xtrain.astype(np.float32)\n",
    "Xtest = Xtest.astype(np.float32)\n",
    "Ytrain = Ytrain.astype(np.float32)\n",
    "Ytest = Ytest.astype(np.float32)\n",
    "Ytrain_ind = Ytrain_ind.astype(np.float32)\n",
    "Ytest_ind = Ytest_ind.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial values\n",
    "\n",
    "max_iter = 15\n",
    "print_period = 100\n",
    "\n",
    "lr = 0.0004\n",
    "reg = 0.01 #smooth parameter\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "batch_sz = 500\n",
    "n_batches = N // batch_sz\n",
    "\n",
    "M = 300\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_init = np.random.randn(D, M) / 28\n",
    "b1_init = np.zeros(M)\n",
    "W2_init = np.random.randn(M, K) / np.sqrt(M)\n",
    "b2_init = np.zeros(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: define theano variables and expressions\n",
    "thX = T.matrix('X')\n",
    "thT = T.matrix('T')\n",
    "W1 = theano.shared(W1_init, 'W1')\n",
    "b1 = theano.shared(b1_init, 'b1')\n",
    "W2 = theano.shared(W2_init, 'W2')\n",
    "b2 = theano.shared(b2_init, 'b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the built-in theano functions to do relu and softmax\n",
    "\n",
    "thZ = relu( thX.dot(W1) + b1 )  \n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrng = RandomStreams()\\n\\nmask1_thX = rng.binomial(n=1, p = 0.8, size = thX.shape)\\nthX = thX * mask1_thX\\n\\n\\nthZ = relu( thX.dot(W1) + b1 )  \\n\\nmask1_thZ = rng.binomial(n=1, p = 0.5, size = thZ.shape)\\nthZ = thZ * mask1_thZ\\n\\nthY = T.nnet.softmax( thZ.dot(W2) + b2 )\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropout \n",
    "\"\"\"\n",
    "rng = RandomStreams()\n",
    "\n",
    "mask1_thX = rng.binomial(n=1, p = 0.8, size = thX.shape)\n",
    "thX = thX * mask1_thX\n",
    "\n",
    "\n",
    "thZ = relu( thX.dot(W1) + b1 )  \n",
    "\n",
    "mask1_thZ = rng.binomial(n=1, p = 0.5, size = thZ.shape)\n",
    "thZ = thZ * mask1_thZ\n",
    "\n",
    "thY = T.nnet.softmax( thZ.dot(W2) + b2 )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function and prediction\n",
    "cost = -(thT * T.log(thY)).sum()\n",
    "\n",
    "#L1 regularization\n",
    "#cost = -(thT * T.log(thY)).sum() + reg*((W1*W1).sum() + (b1*b1).sum() + (W2*W2).sum() + (b2*b2).sum())\n",
    "\n",
    "#L2 regularization\n",
    "#cost = -(thT * T.log(thY)).sum() + reg*(np.abs(W1).sum() + np.abs(b1).sum() + np.abs(W2).sum() + np.abs(b2).sum())\n",
    "\n",
    "prediction = T.argmax(thY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmu = 0.9\\nparams = [W1, b1, W2, b2]\\nvparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\n\\nupdates = []\\n\\nfor p, vp in zip(params, vparams):\\n    update_vp = mu * vp - lr * T.grad(cost, p)\\n    update_p = p + mu * update_vp - lr * T.grad(cost, p)\\n    updates.append((vp, update_vp))\\n    updates.append((p, update_p))\\n    \\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "mu = 0.9\n",
    "\"\"\" \n",
    "#without momentum \n",
    "\n",
    "\n",
    "\n",
    "update_W1 = W1 - lr*T.grad(cost, W1)\n",
    "update_b1 = b1 - lr*T.grad(cost, b1)\n",
    "update_W2 = W2 - lr*T.grad(cost, W2)\n",
    "update_b2 = b2 - lr*T.grad(cost, b2)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)]\n",
    "\n",
    "\n",
    "\n",
    "# this is equivalent to the line above\n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "updates = [(p, p-lr*T.grad(cost, p)) for p in params]\n",
    "\"\"\"\n",
    "\n",
    "# using for loop \n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "updates = []\n",
    "for p in params:\n",
    "    update_p = p - lr * T.grad(cost, p)\n",
    "    updates.append((p, update_p))\n",
    "\n",
    "#With momentum\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "vW1_init = np.zeros((D,M))\n",
    "vb1_init = np.zeros(M)\n",
    "vW2_init = np.zeros((M,K))\n",
    "vb2_init = np.zeros(K)\n",
    "\n",
    "vW1 = theano.shared(vW1_init, 'dW1')\n",
    "vb1 = theano.shared(vb1_init, 'db1')\n",
    "vW2 = theano.shared(vW2_init, 'dW2')\n",
    "vb2 = theano.shared(vb2_init, 'db2')\n",
    "\n",
    "update_vW1 = mu * vW1 - lr * T.grad(cost, W1)\n",
    "update_vb1 = mu * vb1 - lr * T.grad(cost, b1)\n",
    "update_vW2 = mu * vW2 - lr * T.grad(cost, W2)\n",
    "update_vb2 = mu * vb2 - lr * T.grad(cost, b2)\n",
    "\n",
    "update_W1 = W1 + update_vW1\n",
    "update_b1 = b1 + update_vb1\n",
    "update_W2 = W2 + update_vW2\n",
    "update_b2 = b2 + update_vb2\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(vW1, update_vW1), (vb1, update_vb1), (vW2, update_vW2), (vb2, update_vb2)]\n",
    "\n",
    "\n",
    "# this is equivalent to the line above\n",
    "\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = [(p, p + mu * vp -lr * T.grad(cost, p)) for p, vp in zip(params, vparams)] + [(vp, mu * vp - lr * T.grad(cost, p)) for p, vp in zip(params, vparams)]\n",
    "\n",
    "\n",
    "#using for loops\n",
    "mu = 0.9\n",
    "\n",
    "\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = []\n",
    "for p, vp in zip(params, vparams):\n",
    "    update_vp = mu * vp - lr * T.grad(cost, p)\n",
    "    update_p = p + update_vp\n",
    "    updates.append((vp, update_vp))\n",
    "    updates.append((p, update_p))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#with nesterov momentum\n",
    "\n",
    "vW1_init = np.zeros((D,M))\n",
    "vb1_init = np.zeros(M)\n",
    "vW2_init = np.zeros((M,K))\n",
    "vb2_init = np.zeros(K)\n",
    "\n",
    "vW1 = theano.shared(vW1_init, 'dW1')\n",
    "vb1 = theano.shared(vb1_init, 'db1')\n",
    "vW2 = theano.shared(vW2_init, 'dW2')\n",
    "vb2 = theano.shared(vb2_init, 'db2')\n",
    "\n",
    "update_vW1 = mu * vW1 - lr * T.grad(cost, W1)\n",
    "update_vb1 = mu * vb1 - lr * T.grad(cost, b1)\n",
    "update_vW2 = mu * vW2 - lr * T.grad(cost, W2)\n",
    "update_vb2 = mu * vb2 - lr * T.grad(cost, b2)\n",
    "\n",
    "update_W1 = W1 + mu * update_vW1 - lr * T.grad(cost, W1)\n",
    "update_b1 = b1 + mu * update_vb1 - lr * T.grad(cost, b1)\n",
    "update_W2 = W2 + mu * update_vW2 - lr * T.grad(cost, W2)\n",
    "update_b2 = b2 + mu * update_vb2 - lr * T.grad(cost, b2)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(vW1, update_vW1), (vb1, update_vb1), (vW2, update_vW2), (vb2, update_vb2)]\n",
    "\"\"\"\n",
    "\n",
    "#This line is equivalent to the line above\n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = [(p, p + mu * (mu * vp - lr * T.grad(cost, p)) - lr * T.grad(cost, p)) for p, vp in zip(params, vparams)] + [(vp, mu * vp - lr * T.grad(cost, p)) for p, vp in zip(params, vparams)]\n",
    "\"\"\"\n",
    "\n",
    "#using for loops\n",
    "\"\"\"\n",
    "mu = 0.9\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = []\n",
    "\n",
    "for p, vp in zip(params, vparams):\n",
    "    update_vp = mu * vp - lr * T.grad(cost, p)\n",
    "    update_p = p + mu * update_vp - lr * T.grad(cost, p)\n",
    "    updates.append((vp, update_vp))\n",
    "    updates.append((p, update_p))\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepsilon = 1e-8\\n\\nparams = [W1, b1, W2, b2]\\ncparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\nupdates = []\\n\\nfor p, cp in zip(params, cparams):\\n    update_cp = cp + T.grad(cost, p) * T.grad(cost, p)\\n    update_p = p - lr * T.grad(cost, p)/(T.sqrt(update_cp) + epsilon)\\n    updates.append((cp, update_cp))\\n    updates.append((p, update_p))\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AdaGrad\n",
    "\"\"\"\n",
    "lr = 0.0004\n",
    "epsilon = 0.0000001\n",
    "\n",
    "\n",
    "cW1_init = np.zeros((D,M))\n",
    "cb1_init = np.zeros(M)\n",
    "cW2_init = np.zeros((M,K))\n",
    "cb2_init = np.zeros(K)\n",
    "\n",
    "cW1 = theano.shared(cW1_init, 'cW1')\n",
    "cb1 = theano.shared(cb1_init, 'cb1')\n",
    "cW2 = theano.shared(cW2_init, 'cW2')\n",
    "cb2 = theano.shared(cb2_init, 'cb2')\n",
    "\n",
    "update_cW1 = cW1 + T.grad(cost, W1) * T.grad(cost, W1)\n",
    "update_cb1 = cb1 + T.grad(cost, b1) * T.grad(cost, b1)\n",
    "update_cW2 = cW2 + T.grad(cost, W2) * T.grad(cost, W2)\n",
    "update_cb2 = cb2 + T.grad(cost, b2) * T.grad(cost, b2)\n",
    "\n",
    "update_W1 = W1 - lr * T.grad(cost, W1)/(T.sqrt(update_cW1) + epsilon)\n",
    "update_b1 = b1 - lr * T.grad(cost, b1)/(T.sqrt(update_cb1) + epsilon)\n",
    "update_W2 = W2 - lr * T.grad(cost, W2)/(T.sqrt(update_cW2) + epsilon)\n",
    "update_b2 = b2 - lr * T.grad(cost, b2)/(T.sqrt(update_cb2) + epsilon)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(cW1, update_cW1), (cb1, update_cb1), (cW2, update_cW2), (cb2, update_cb2)]\n",
    "\"\"\"\n",
    "# this code is same as above lines\n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = [ (p, p - lr * T.grad(cost, p)/(T.sqrt(cp + T.grad(cost, p) * T.grad(cost, p)) + epsilon)) for p, cp in zip(params, cparams)] + [(cp, cp + T.grad(cost, p) * T.grad(cost, p)) for p, cp in zip(params, cparams)]\n",
    "\"\"\"\n",
    "\n",
    "# using for loops\n",
    "\"\"\"\n",
    "epsilon = 1e-8\n",
    "\n",
    "params = [W1, b1, W2, b2]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "updates = []\n",
    "\n",
    "for p, cp in zip(params, cparams):\n",
    "    update_cp = cp + T.grad(cost, p) * T.grad(cost, p)\n",
    "    update_p = p - lr * T.grad(cost, p)/(T.sqrt(update_cp) + epsilon)\n",
    "    updates.append((cp, update_cp))\n",
    "    updates.append((p, update_p))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = 0.0004\\nepsilon = 0.0000001\\ndecay = 0.999\\n\\nparams = [W1, b1, W2, b2]\\ncparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\nupdates = []\\n\\nfor p, cp in zip(params, cparams):\\n    update_cp = decay * cp + (1-decay) * T.grad(cost, p) * T.grad(cost, p)\\n    update_p = p - lr * T.grad(cost, p)/(T.sqrt(update_cp)+epsilon)\\n    updates.append((cp, update_cp))\\n    updates.append((p, update_p))\\n    \\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMS\n",
    "\"\"\"\n",
    "lr = 0.0004\n",
    "epsilon = 0.0000001\n",
    "decay = 0.999\n",
    "\n",
    "cW1_init = np.zeros((D,M))\n",
    "cb1_init = np.zeros(M)\n",
    "cW2_init = np.zeros((M,K))\n",
    "cb2_init = np.zeros(K)\n",
    "\n",
    "cW1 = theano.shared(cW1_init, 'cW1')\n",
    "cb1 = theano.shared(cb1_init, 'cb1')\n",
    "cW2 = theano.shared(cW2_init, 'cW2')\n",
    "cb2 = theano.shared(cb2_init, 'cb2')\n",
    "\n",
    "update_cW1 = decay * cW1 + (1 - decay) * T.grad(cost, W1) * T.grad(cost, W1)\n",
    "update_cb1 = decay * cb1 + (1 - decay) * T.grad(cost, b1) * T.grad(cost, b1)\n",
    "update_cW2 = decay * cW2 + (1 - decay) * T.grad(cost, W2) * T.grad(cost, W2)\n",
    "update_cb2 = decay * cb2 + (1 - decay) * T.grad(cost, b2) * T.grad(cost, b2)\n",
    "\n",
    "update_W1 = W1 - lr * T.grad(cost, W1)/(T.sqrt(update_cW1) + epsilon)\n",
    "update_b1 = b1 - lr * T.grad(cost, b1)/(T.sqrt(update_cb1) + epsilon)\n",
    "update_W2 = W2 - lr * T.grad(cost, W2)/(T.sqrt(update_cW2) + epsilon)\n",
    "update_b2 = b2 - lr * T.grad(cost, b2)/(T.sqrt(update_cb2) + epsilon)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(cW1, update_cW1), (cb1, update_cb1), (cW2, update_cW2), (cb2, update_cb2)]\n",
    "\"\"\"\n",
    "#This line is same as above lines\n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "updates = [(p, p - lr * T.grad(cost, p)/(T.sqrt(decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p)) + epsilon)) for p, cp in zip(params, cparams)] + [ (cp, decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p)) for p, cp in zip(params, cparams)]\n",
    "\"\"\"\n",
    "\n",
    "# using for loops\n",
    "\"\"\"\n",
    "lr = 0.0004\n",
    "epsilon = 0.0000001\n",
    "decay = 0.999\n",
    "\n",
    "params = [W1, b1, W2, b2]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "updates = []\n",
    "\n",
    "for p, cp in zip(params, cparams):\n",
    "    update_cp = decay * cp + (1-decay) * T.grad(cost, p) * T.grad(cost, p)\n",
    "    update_p = p - lr * T.grad(cost, p)/(T.sqrt(update_cp)+epsilon)\n",
    "    updates.append((cp, update_cp))\n",
    "    updates.append((p, update_p))\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMS with momentum and ADAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlr = 0.0004\\nepsilon = 0.0000001\\ndecay = 0.999\\nmu = 0.9\\n\\n#using for loops\\nparams = [W1, b1, W2, b2]\\nvparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\ncparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\nupdates = []\\n\\nfor p, vp, cp in zip(params, vparams, cparams):\\n    update_vp = mu * vp - lr * T.grad(cost, p)\\n    update_cp = decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p)  \\n    update_p = p + update_vp/(T.sqrt(update_cp) + epsilon)\\n    \\n    updates.append((vp, update_vp))\\n    updates.append((cp, update_cp))\\n    updates.append((p, update_p))\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMS with momentum  \n",
    "\"\"\"\n",
    "\n",
    "lr = 0.0004\n",
    "epsilon = 0.0000001\n",
    "decay = 0.999\n",
    "mu = 0.9\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "vW1_init = np.zeros((D,M))\n",
    "vb1_init = np.zeros(M)\n",
    "vW2_init = np.zeros((M,K))\n",
    "vb2_init = np.zeros(K)\n",
    "\n",
    "vW1 = theano.shared(vW1_init, 'dW1')\n",
    "vb1 = theano.shared(vb1_init, 'db1')\n",
    "vW2 = theano.shared(vW2_init, 'dW2')\n",
    "vb2 = theano.shared(vb2_init, 'db2')\n",
    "\n",
    "cW1_init = np.zeros((D,M))\n",
    "cb1_init = np.zeros(M)\n",
    "cW2_init = np.zeros((M,K))\n",
    "cb2_init = np.zeros(K)\n",
    "\n",
    "cW1 = theano.shared(cW1_init, 'cW1')\n",
    "cb1 = theano.shared(cb1_init, 'cb1')\n",
    "cW2 = theano.shared(cW2_init, 'cW2')\n",
    "cb2 = theano.shared(cb2_init, 'cb2')\n",
    "\n",
    "update_vW1 = mu * vW1 - lr * T.grad(cost, W1)\n",
    "update_vb1 = mu * vb1 - lr * T.grad(cost, b1)\n",
    "update_vW2 = mu * vW2 - lr * T.grad(cost, W2)\n",
    "update_vb2 = mu * vb2 - lr * T.grad(cost, b2)\n",
    "\n",
    "update_cW1 = decay * cW1 + (1 - decay) * T.grad(cost, W1) * T.grad(cost, W1)\n",
    "update_cb1 = decay * cb1 + (1 - decay) * T.grad(cost, b1) * T.grad(cost, b1)\n",
    "update_cW2 = decay * cW2 + (1 - decay) * T.grad(cost, W2) * T.grad(cost, W2)\n",
    "update_cb2 = decay * cb2 + (1 - decay) * T.grad(cost, b2) * T.grad(cost, b2)\n",
    "\n",
    "update_W1 = W1 + update_vW1/(T.sqrt(update_cW1) + epsilon)\n",
    "update_b1 = b1 + update_vb1/(T.sqrt(update_cb1) + epsilon)\n",
    "update_W2 = W2 + update_vW2/(T.sqrt(update_cW2) + epsilon)\n",
    "update_b2 = b2 + update_vb2/(T.sqrt(update_cb2) + epsilon)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(vW1, update_vW1), (vb1, update_vb1), (vW2, update_vW2), (vb2, update_vb2)] + [(cW1, update_cW1), (cb1, update_cb1), (cW2, update_cW2), (cb2, update_cb2)]\n",
    "\"\"\"\n",
    "# the follwing code is same as above \n",
    "\"\"\"\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "update_tensor = [(p, p + mu * vp - lr * T.grad(cost, p)/(T.sqrt(decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p)) + epsilon) ) for p, vp, cp in zip(params, vparams, cparams)]\n",
    "update_c = [(cp, decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p) ) for p, cp in zip(params, cparams)]\n",
    "update_v = [(vp, mu * vp - lr * T.grad(cost, p)) for p, vp in zip(params, vparams)]\n",
    "\n",
    "updates = update_tensor + update_c + update_v\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#using for loops\n",
    "\"\"\"\n",
    "lr = 0.0004\n",
    "epsilon = 0.0000001\n",
    "decay = 0.999\n",
    "mu = 0.9\n",
    "\n",
    "#using for loops\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "cparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "updates = []\n",
    "\n",
    "for p, vp, cp in zip(params, vparams, cparams):\n",
    "    update_vp = mu * vp - lr * T.grad(cost, p)\n",
    "    update_cp = decay * cp + (1 - decay) * T.grad(cost, p) * T.grad(cost, p)  \n",
    "    update_p = p + update_vp/(T.sqrt(update_cp) + epsilon)\n",
    "    \n",
    "    updates.append((vp, update_vp))\n",
    "    updates.append((cp, update_cp))\n",
    "    updates.append((p, update_p))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlr = 1e-3\\nbeta_1 = 0.9\\nbeta_2 = 0.999\\neps = 1e-8\\n\\n\\nvW1_init = np.zeros((D,M))\\nvb1_init = np.zeros(M)\\nvW2_init = np.zeros((M,K))\\nvb2_init = np.zeros(K)\\n\\nvW1 = theano.shared(vW1_init, 'dW1')\\nvb1 = theano.shared(vb1_init, 'db1')\\nvW2 = theano.shared(vW2_init, 'dW2')\\nvb2 = theano.shared(vb2_init, 'db2')\\n\\nmW1_init = np.zeros((D,M))\\nmb1_init = np.zeros(M)\\nmW2_init = np.zeros((M,K))\\nmb2_init = np.zeros(K)\\n\\nmW1 = theano.shared(mW1_init, 'cW1')\\nmb1 = theano.shared(mb1_init, 'cb1')\\nmW2 = theano.shared(mW2_init, 'cW2')\\nmb2 = theano.shared(mb2_init, 'cb2')\\n\\nt = theano.shared(float(0.))\\n\\nupdate_t = t + 1 \\n\\n\\n\\nupdate_mW1 = beta_1 * mW1 + (1-beta_1) * T.grad(cost, W1)\\nupdate_mb1 = beta_1 * mb1 + (1-beta_1) * T.grad(cost, b1)\\nupdate_mW2 = beta_1 * mW2 + (1-beta_1) * T.grad(cost, W2)\\nupdate_mb2 = beta_1 * mb2 + (1-beta_1) * T.grad(cost, b2)\\n\\nupdate_vW1 = beta_2 * vW1 + (1-beta_2) * T.grad(cost, W1) * T.grad(cost, W1)\\nupdate_vb1 = beta_2 * vb1 + (1-beta_2) * T.grad(cost, b1) * T.grad(cost, b1)\\nupdate_vW2 = beta_2 * vW2 + (1-beta_2) * T.grad(cost, W2) * T.grad(cost, W2)\\nupdate_vb2 = beta_2 * vb2 + (1-beta_2) * T.grad(cost, b2) * T.grad(cost, b2)\\n\\n\\nhat_mW2 = update_mW2/(1-beta_1**update_t)\\nhat_mb2 = update_mb2/(1-beta_1**update_t)\\nhat_mW1 = update_mW1/(1-beta_1**update_t)\\nhat_mb1 = update_mb1/(1-beta_1**update_t)\\n\\nhat_vW2 = update_vW2/(1-beta_2**update_t)\\nhat_vb2 = update_vb2/(1-beta_2**update_t)\\nhat_vW1 = update_vW1/(1-beta_2**update_t)\\nhat_vb1 = update_vb1/(1-beta_2**update_t)\\n    \\n    \\nupdate_W2 = W2 - lr * hat_mW2/T.sqrt(hat_vW2 + eps)\\nupdate_b2 = b2 - lr * hat_mb2/T.sqrt(hat_vb2 + eps)\\nupdate_W1 = W1 - lr * hat_mW1/T.sqrt(hat_vW1 + eps)\\nupdate_b1 = b1 - lr * hat_mb1/T.sqrt(hat_vb1 + eps)\\n\\nupdates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(vW1, update_vW1), (vb1, update_vb1), (vW2, update_vW2), (vb2, update_vb2)] + [(mW1, update_mW1), (mb1, update_mb1), (mW2, update_mW2), (mb2, update_mb2)] + [(t, update_t)]\\n\\n# the code is correct.\\n\\n\\nupdates = []\\nparams = [W1, b1, W2, b2]\\nvparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\nmparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\\n\\nt = theano.shared(float(0.))\\nupdate_t = t + 1 \\n\\nfor p, vp, mp in zip(params, vparams, mparams):\\n    update_mp = beta_1 * mp + (1-beta_1) * T.grad(cost, p)\\n    update_vp = beta_2 * vp + (1-beta_2) * T.grad(cost, p) * T.grad(cost, p)\\n    hat_mp = update_mp/(1-beta_1**update_t)\\n    hat_vp = update_vp/(1-beta_2**update_t)\\n    update_p = p - lr * hat_mp/T.sqrt(hat_vp + eps)\\n    \\n    updates.append((p, update_p))\\n    updates.append((mp, update_mp))\\n    updates.append((vp, update_vp))\\n    \\nupdates.append((t, update_t))\\n    \\n\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ADAM Optimizer\n",
    "\n",
    "\"\"\"\n",
    "lr = 1e-3\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "eps = 1e-8\n",
    "\n",
    "\n",
    "vW1_init = np.zeros((D,M))\n",
    "vb1_init = np.zeros(M)\n",
    "vW2_init = np.zeros((M,K))\n",
    "vb2_init = np.zeros(K)\n",
    "\n",
    "vW1 = theano.shared(vW1_init, 'dW1')\n",
    "vb1 = theano.shared(vb1_init, 'db1')\n",
    "vW2 = theano.shared(vW2_init, 'dW2')\n",
    "vb2 = theano.shared(vb2_init, 'db2')\n",
    "\n",
    "mW1_init = np.zeros((D,M))\n",
    "mb1_init = np.zeros(M)\n",
    "mW2_init = np.zeros((M,K))\n",
    "mb2_init = np.zeros(K)\n",
    "\n",
    "mW1 = theano.shared(mW1_init, 'cW1')\n",
    "mb1 = theano.shared(mb1_init, 'cb1')\n",
    "mW2 = theano.shared(mW2_init, 'cW2')\n",
    "mb2 = theano.shared(mb2_init, 'cb2')\n",
    "\n",
    "t = theano.shared(float(0.))\n",
    "\n",
    "update_t = t + 1 \n",
    "\n",
    "\n",
    "\n",
    "update_mW1 = beta_1 * mW1 + (1-beta_1) * T.grad(cost, W1)\n",
    "update_mb1 = beta_1 * mb1 + (1-beta_1) * T.grad(cost, b1)\n",
    "update_mW2 = beta_1 * mW2 + (1-beta_1) * T.grad(cost, W2)\n",
    "update_mb2 = beta_1 * mb2 + (1-beta_1) * T.grad(cost, b2)\n",
    "\n",
    "update_vW1 = beta_2 * vW1 + (1-beta_2) * T.grad(cost, W1) * T.grad(cost, W1)\n",
    "update_vb1 = beta_2 * vb1 + (1-beta_2) * T.grad(cost, b1) * T.grad(cost, b1)\n",
    "update_vW2 = beta_2 * vW2 + (1-beta_2) * T.grad(cost, W2) * T.grad(cost, W2)\n",
    "update_vb2 = beta_2 * vb2 + (1-beta_2) * T.grad(cost, b2) * T.grad(cost, b2)\n",
    "\n",
    "\n",
    "hat_mW2 = update_mW2/(1-beta_1**update_t)\n",
    "hat_mb2 = update_mb2/(1-beta_1**update_t)\n",
    "hat_mW1 = update_mW1/(1-beta_1**update_t)\n",
    "hat_mb1 = update_mb1/(1-beta_1**update_t)\n",
    "\n",
    "hat_vW2 = update_vW2/(1-beta_2**update_t)\n",
    "hat_vb2 = update_vb2/(1-beta_2**update_t)\n",
    "hat_vW1 = update_vW1/(1-beta_2**update_t)\n",
    "hat_vb1 = update_vb1/(1-beta_2**update_t)\n",
    "    \n",
    "    \n",
    "update_W2 = W2 - lr * hat_mW2/T.sqrt(hat_vW2 + eps)\n",
    "update_b2 = b2 - lr * hat_mb2/T.sqrt(hat_vb2 + eps)\n",
    "update_W1 = W1 - lr * hat_mW1/T.sqrt(hat_vW1 + eps)\n",
    "update_b1 = b1 - lr * hat_mb1/T.sqrt(hat_vb1 + eps)\n",
    "\n",
    "updates = [(W1, update_W1), (b1, update_b1), (W2, update_W2), (b2, update_b2)] + [(vW1, update_vW1), (vb1, update_vb1), (vW2, update_vW2), (vb2, update_vb2)] + [(mW1, update_mW1), (mb1, update_mb1), (mW2, update_mW2), (mb2, update_mb2)] + [(t, update_t)]\n",
    "\n",
    "# the code is correct.\n",
    "\n",
    "\n",
    "updates = []\n",
    "params = [W1, b1, W2, b2]\n",
    "vparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "mparams = [theano.shared(np.zeros_like(p.get_value())) for p in params]\n",
    "\n",
    "t = theano.shared(float(0.))\n",
    "update_t = t + 1 \n",
    "\n",
    "for p, vp, mp in zip(params, vparams, mparams):\n",
    "    update_mp = beta_1 * mp + (1-beta_1) * T.grad(cost, p)\n",
    "    update_vp = beta_2 * vp + (1-beta_2) * T.grad(cost, p) * T.grad(cost, p)\n",
    "    hat_mp = update_mp/(1-beta_1**update_t)\n",
    "    hat_vp = update_vp/(1-beta_2**update_t)\n",
    "    update_p = p - lr * hat_mp/T.sqrt(hat_vp + eps)\n",
    "    \n",
    "    updates.append((p, update_p))\n",
    "    updates.append((mp, update_mp))\n",
    "    updates.append((vp, update_vp))\n",
    "    \n",
    "updates.append((t, update_t))\n",
    "    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    updates = updates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another function for this because we want it over the whole dataset\n",
    "get_prediction = theano.function(\n",
    "    inputs=[thX, thT],\n",
    "    outputs=[cost, prediction],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0, cost_value: 1768.204, error: 0.524\n",
      "Cost / err at iteration i=1, j=0, cost_value: 264.826, error: 0.073\n",
      "Cost / err at iteration i=2, j=0, cost_value: 209.089, error: 0.057\n",
      "Cost / err at iteration i=3, j=0, cost_value: 181.083, error: 0.051\n",
      "Cost / err at iteration i=4, j=0, cost_value: 162.486, error: 0.042\n",
      "Cost / err at iteration i=5, j=0, cost_value: 152.728, error: 0.040\n",
      "Cost / err at iteration i=6, j=0, cost_value: 143.758, error: 0.036\n",
      "Cost / err at iteration i=7, j=0, cost_value: 136.988, error: 0.036\n",
      "Cost / err at iteration i=8, j=0, cost_value: 135.784, error: 0.036\n",
      "Cost / err at iteration i=9, j=0, cost_value: 127.161, error: 0.035\n",
      "Cost / err at iteration i=10, j=0, cost_value: 133.409, error: 0.035\n",
      "Cost / err at iteration i=11, j=0, cost_value: 121.087, error: 0.031\n",
      "Cost / err at iteration i=12, j=0, cost_value: 127.101, error: 0.032\n",
      "Cost / err at iteration i=13, j=0, cost_value: 128.664, error: 0.033\n",
      "Cost / err at iteration i=14, j=0, cost_value: 126.782, error: 0.033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = []\n",
    "for i in range(max_iter):\n",
    "    for j in range(n_batches):\n",
    "        Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "        Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "        train(Xbatch, Ybatch)\n",
    "        if j % print_period == 0:\n",
    "            cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "            err = error_rate(prediction_val, Ytest)\n",
    "            print(\"Cost / err at iteration i=%d, j=%d, cost_value: %.3f, error: %.3f\" % (i, j, cost_val, err))\n",
    "            costs.append(cost_val)\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
